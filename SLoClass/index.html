<HTML>

<HEAD>

<TITLE>RSL2019: A Realistic Speech Localization Corpus</TITLE>

</HEAD>

<BODY BGCOLOR="FFFFFF">
<p>&nbsp;</p>
<center>

<h1>SLoClas: A Database for Joint Sound Localization and Classification</h2>
<h2><pre><a>Xinyuan Qian</a>   <a href="https://scholar.google.com.sg/citations?user=oEESlDQAAAAJ&hl=en&oi=ao">Bidisha Sharma</a>   <a href="https://scholar.google.com.sg/citations?user=BLLXxDoAAAAJ&hl=en&oi=ao">Amine El Abridi</a>   <a href="https://scholar.google.com.sg/citations?user=V8XFDQcAAAAJ&hl=en&oi=ao">Haizhou Li</a></pre></h2>
<h2><pre> Department of Electrical and Computer Engineering, National University of Singapore, Singapore</pre></h2>
<h2><pre> *Department of Electrical Engineering, Indian Institute of Technology Dharwad, Dharwad, India</pre></h2> 
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>  
 </center> 
 
   
<center><img src="images/RSL2019Github.png" width="1000" height="426" align="BOTTOM" /></center>
 
<p>&nbsp;</p>
 <p>&nbsp;</p>
  <blockquote>
<font size="+2"><p>In this work, we present the development of a new database for studying and analyzing joint framework of sound localization and classification that we refer to as Sound Localization and Classification ({\it SLoClas}) corpus. The SLoClas database contains a total of 23.27 hours of different environmental sounds data recorded using a four channel microphone array, and played over a loudspeaker from different directions of arrival (DOA). We consider 10 sound classes with around 100 examples for each class, which are played over the loudspeaker positioned at different angles from the microphone array at 1.5 metre distance. We vary the DOA from 0 to 360 degree angle at an interval of 5 degree. Additionally, we incorporate 6 different types of outdoor noise data recorded from 4 angles using the same equipment to facilitate the study of robustness. Furthermore, we present the experimental results and analysis on a neural network based joint model for sound localization and classification on the created SLoClas database. We achieve accuracy of 95.21\% and 80.01\% for sound localization and classification, respectively, using the joint model. To provide a common platform, we publicly release this database for research purpose.</p></font>
</blockquote>
<p>&nbsp;</p>
 
<h3><font size="+3">Link to Download the database:</font></h3>
 
<font size="+3"><p><a href="https://zenodo.org/record/4925958#.YMMyhiYRXCI">Click Here</a><br /> </p></font>
</blockquote>
<p>&nbsp;</p>
 
<h3><font size="+3">Reference:</font></h3> 
 
<font size="+2"><p>If you use this database please cite the following paper : </p></font>
  
<font size="+2"><p> Rohan Sheelvant, Bidisha Sharma, Maulik Madhavi, Rohan Kumar Das, S.R.M. Prasanna and Haizhou Li “RSL2019: A Realistic Speech Localization Corpus” in Proc. International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (Oriental COCOSDA), Cebu City, Philippines, October 2019, <a href="https://www.researchgate.net/publication/336459196_RSL2019_A_Realistic_Speech_Localization_Corpus">Link</a><br />  </p>
<p>&nbsp;</p></font>
  <hr />

</BODY>

</HTML> 

