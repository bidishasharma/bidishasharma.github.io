<HTML>

<HEAD>

<TITLE>RSL2019: A Realistic Speech Localization Corpus</TITLE>

</HEAD>

<BODY BGCOLOR="FFFFFF">
<p>&nbsp;</p>
<center>

<h1>RSL2019: A Realistic Speech Localization Corpus</h2>
  <h2><pre><a href="https://www.researchgate.net/publication/336459196_RSL2019_A_Realistic_Speech_Localization_Corpus">Bidisha Sharma</a>      <a href="https://scholar.google.com.sg/citations?user=z8_x7C8AAAAJ&hl=en&oi=ao">Haizhou Li</a></pre></h2>
<h2><pre> Department of Electrical and Computer Engineering,<br />National University of Singapore, Singapore</pre></h2>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>  
 </center> 
<center><img src="AlignmentV6.png" width="1326" height="426" align="BOTTOM" /></center>
  
  
<h2>ABSTRACT</h2>
<p>&nbsp;</p>
 <p>&nbsp;</p>
  <blockquote>
<font size="+3"><p>In this work, we present the development of a new database for speech localization that we refer to as Realistic Speech Localization 2019 (RSL2019) corpus. The corpus is designed for the study of sound source localization in real-world applications. The RSL2019 corpus is a continuing effort, which presently contains 22.60 hours of speech data, recorded using a four channel microphone array, and played over a loudspeaker from different directions of arrival (DOA). We consider 180
speech utterances spoken by 6 speakers, selected from RSR2015 database, which are played over the loudspeaker positioned at
different angles and distances from the microphone array. We vary the DOA from 0 to 360 degree angle at an interval of 5 degree,at 1 metre and 1.5 metre distance. From each positionand DOA, we also record white noise to study the robustness, and
time stretched pulse to generate the transfer function for speech localization algorithm. Furthermore, we present the experimental results and analysis on state-of-the-art sound source localization algorithm using the open source HARK toolkit on the created RSL2019 database. This database will be provided for research purpose upon request to the authors..</p></font>
</blockquote>
<p>&nbsp;</p>  
<h2><font size="+3">Examples of Speech-to-Singing Coversion</font></h2>
<p>&nbsp;</p>
<h3><font size="+3">Vocoded Singing:</font></h3>
<p>&nbsp;</p>  
<p><font size="+3"><a href="Vocoded-1.wav">WAV1</a>&nbsp; <a href="Vocoded-2.wav">WAV2</a>&nbsp; <a href="Vocoded-3.wav">WAV3</a> &nbsp;<a href="Vocoded-4.wav">WAV4</a> &nbsp;<a href="Vocoded-5.wav">WAV5</a></font></p>
<p>&nbsp;</p>
<h3><font size="+3">Converted Singing Voice using Baseline Alignment Method:</font></h3>
<p>&nbsp;</p>
<p><font size="+3"><a href="Baseline-1.wav">WAV1</a> &nbsp;<a href="Baseline-2.wav">WAV2</a>&nbsp; <a href="Baseline-3.wav">WAV3</a> &nbsp;<a href="Baseline-4.wav">WAV4</a> &nbsp;<a href="Baseline-5.wav">WAV5</a></font></p>
<p>&nbsp;</p>
<h3><font size="+3">Converted Singing Voice using Proposed Alignment Method:</font></h3>
<p>&nbsp;</p>
<p><font size="+3"><a href="Proposed-1.wav">WAV1</a> &nbsp;<a href="Proposed-2.wav">WAV2</a> &nbsp;<a href="Proposed-3.wav">WAV3</a>&nbsp; <a href="Proposed-4.wav">WAV4</a> &nbsp;<a href="Proposed-5.wav">WAV5</a></font></p>
<p>&nbsp;</p>  
<p>&nbsp;</p>  
<p>&nbsp;</p>  
  <hr />

</BODY>

</HTML> 

